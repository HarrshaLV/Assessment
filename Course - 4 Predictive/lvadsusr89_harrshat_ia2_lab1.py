# -*- coding: utf-8 -*-
"""LVADSUSR89_harrshat_IA2_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m8MvDKY4Z7FRhuwMBIcJQ-Zfd5hCJb33
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df=pd.read_csv("/content/winequality-red.csv")

df.isnull().sum()

df.head()

df['quality'].value_counts()

df.drop_duplicates(inplace=True)

df.fillna(method="ffill",inplace=True)

df.isnull().sum()

df.corr()

sns.heatmap(df.corr(),annot=True)

df['quality'] = np.where((df['quality'] >=3)& (df['quality'] <=6), 0,1)
df['quality'].value_counts()

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV

from sklearn.preprocessing import StandardScaler
std = StandardScaler()
df.iloc[:,:-1]=std.fit_transform(df.iloc[:,:-1])

X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)

from sklearn.neighbors import KNeighborsClassifier

error_rate = []
for i in range(1, 40):

	knn = KNeighborsClassifier(n_neighbors = i)
	knn.fit(X_train, y_train)
	pred_i = knn.predict(X_test)
	error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize =(10, 6))
plt.plot(range(1, 40), error_rate, color ='blue',
				linestyle ='dashed', marker ='o',
		markerfacecolor ='red', markersize = 10)

plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

classifier2 = KNeighborsClassifier(n_neighbors= 21, metric = 'manhattan', p = 2,weights='uniform')
classifier2.fit(X_train,y_train)

#Predicting the ouput from input data (x_train) and (y_train)
y_pred1 = classifier2.predict(X_train)
y_pred2 = classifier2.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy score of test data set:",accuracy_score(y_test, y_pred2))