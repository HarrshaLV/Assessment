# -*- coding: utf-8 -*-
"""LVADSUSR89-HarrshaT-FA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ww-DXChDNxzUHGf4Hj5o8-0iJOvrOsIY
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""## 1. Load Dataset
- Import dataset
- Examine basic information using pandas
"""

file_path = '/content/Walmart_Dataset_Python_Final_Assessment.xlsx'
df = pd.read_excel(file_path)
print(df)

df.info()

df.describe()

"""## 2. Data Cleaning
- Check and handle missing values. Fill or drop them.
- Identify and resolve duplicate data entries.

"""

df.isnull().sum()

df.drop_duplicates(inplace=True)

"""## 3. Descriptive Statistics

"""

df.describe()

df.var()

"""## 4. Data Visualization
- Use charts and plots (like histogram, scatter plot, box plot, bar chart, pie chart) to visualize data distributions and relationships)
"""

#Creating new columns to add to the dataframe
df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])
df['Order Year'] = pd.to_datetime(df['Order Date']).dt.year

salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(False)
plt.legend()

plt.figure(figsize=(5, 5))
sns.barplot(x='Category', y='Sales', data=df)
plt.title('Sales per Category')
plt.xlabel('Category')
plt.ylabel('Sales')
plt.xticks(rotation=90)

plt.figure(figsize=(5, 5))
sns.scatterplot(x='Quantity', y='Profit', data=df)
plt.title('Profit v/s Quantity')
plt.xlabel('Quantity')
plt.ylabel('Profit')

plt.scatter(df['Sales'], df['Category'], color='orange')
plt.xlabel('Sales')
plt.ylabel('Category')
plt.title('Sales vs Category')

df['Category'].value_counts().plot(kind='bar', color='green')
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Frequency of Categories')
plt.xticks(rotation=90)

category_counts = df['Category'].value_counts()
plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140)
plt.axis('equal')
plt.title('Proportion of different product categories')

category_counts = df['Category'].value_counts()
plt.bar(category_counts.index, category_counts.values, color='orange')
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Distribution of Categories')
plt.xticks(rotation=90)

"""## 5. Identifying relationships
- Explore correlations between different variables

"""

df.corr()

"""##6. Anomaly detection
- Identify and analyse any outliers or unusual data points

"""

# Calculating z-scores for 'Sales' and 'Profit' columns of Walmart Dataset
z_scores_sales = np.abs((df['Sales'] - df['Sales'].mean()) / df['Sales'].std())
outliers_sales = df[z_scores_sales > 3]
print("***************************Outliers in Sales:*****************************")
print(outliers_sales)
print("**************************************************************************")
# A datapoint is an outlier here if z-score > 3
z_scores_profit = np.abs((df['Profit'] - df['Profit'].mean()) / df['Profit'].std())
outliers_profit = df[z_scores_profit > 3]
print("***************************Outliers in Profit:*****************************")
print(outliers_profit)

"""## 7. Data Discovery

"""

df['Order Month'] = pd.to_datetime(df['Order Date']).dt.month
salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit')
plt.legend()

salesData = df.groupby('Order Month')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Month')['Profit'].sum()
profitData.plot(label='Profit')
plt.legend()

total_sales = df.groupby(['Order Year', 'Category'])['Sales'].sum().reset_index()
total_sales['Growth'] = total_sales.groupby('Category')['Sales'].pct_change() * 100
most_growth_category = total_sales.groupby('Category')['Growth'].mean().idxmax()
print("Product category that had the highest growth is: ", most_growth_category)

df['OrderDate'] = pd.to_datetime(df['Order Date'])
df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['TimeBetweenOrders'] = df.groupby('EmailID')['Order Date'].diff()
average_time_between_orders = df.groupby('EmailID')['TimeBetweenOrders'].mean()

print("Average time between orders placed by each customer: ")
print(average_time_between_orders)
print(average_time_between_orders.mean())

df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('Category')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery)

df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('EmailID')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery.mean())

customer_orderamount = df.groupby('EmailID')['Sales'].sum().reset_index()
top_10_percent = int(len(customer_orderamount) * 0.1)
highvalue_customers = customer_orderamount.nlargest(top_10_percent, 'Sales')
print(highvalue_customers)

customer_order_amounts = df.groupby('EmailID')['Quantity'].sum().reset_index()
top10percent = int(len(customer_order_amounts) * 0.1)
highvalue_customers = customer_order_amounts.nlargest(top10percent, 'Quantity')
print(highvalue_customers)

